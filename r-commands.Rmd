---
title: "Parsing for R commands"
author: "csiu"
date: "April 24, 2017"
output:
  html_document:
    keep_md: yes
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

----

Iâ€™ll be teaching an R workshop in a couple days based on the [R for Reproducible Scientific Analysis](http://swcarpentry.github.io/r-novice-gapminder/) Software Carpentry lesson plan (lessons 1-10). To get a copy of the R commands (so that I can try them out), I could either (A) copy everything by hand or (B) automatically scrape the commands.

*If you know me, then the choice is pretty obvious...*

In this post, I scrape the R commands using R and [`rvest`](https://github.com/hadley/rvest).

## Getting the syllabus

`read_html` reads the html from a given url and `html_nodes` selects the particular nodes of an HTML document.

```{r message=FALSE}
# Packages I use
library(rvest)
library(dplyr)
library(purrr)
```

```{r}
main_url <- "http://swcarpentry.github.io/r-novice-gapminder/"
```

```{r}
# Get HTML
syllabus <-
  read_html(main_url) %>%
  html_nodes("body div.syllabus table td.col-md-3 a")

# Extract relevant fields & make data frame
(syllabus <-
  data.frame(
    label = html_text(syllabus),
    href = html_attr(syllabus, "href"),
    stringsAsFactors = FALSE
  ) %>%
  mutate(
    lesson_plan = ifelse(grepl("\\d{2}", href),
                         sub(".*(\\d{2}).*", "\\1",  href),
                         "00") %>% as.integer()
  )
) %>% knitr::kable()
```

## Getting the commands from one page

I first extract the R commands from 1 page, and then I can generalize to the other pages. Fortunately, the parsing is easy as all the R commands are tagged by `<div style="r highlighter-rouge">` elements.

```{r}
child_url <- paste0(main_url, syllabus[2,"href"])
```

```{r}
# Extract the commands
cmds <-
  read_html(child_url) %>%
  html_nodes("div.r,highlighter-rouge") %>%
  html_nodes("code") %>%
  html_text()
```

```{r results='asis'}
# Display the commands by Markdown fashion
counter = 1
for (cmd in cmds) {
  cmd <-
    paste0("    ", cmd) %>%
    {gsub("\n", "\n    ", .)} %>%
    {gsub("\n    $", "\n", .)}
  cat(cmd)

  ## As this is a test, print only 5 commands
  if (counter < 5){
    counter <- counter + 1
  } else {
    break
  }
}
```

### Modularized functionality

Next I generalize the parsing of R commands from one page to allow parsing of other pages. The commands are also encapsulated by a function for modularity.

```{r}
get_cmds <- function(href, is_tidy=TRUE) {
  child_url <- paste0(main_url, href)

  cmds <-
    read_html(child_url) %>%
    html_nodes("div.r,highlighter-rouge") %>%
    html_nodes("code") %>%
    html_text()

  if (is_tidy) {
    lapply(cmds, function(cmd){
      paste0("    ", cmd) %>%
      {gsub("\n", "\n    ", .)} %>%
      {gsub("\n    $", "\n", .)}
    }) %>%
      unlist()
  } else {
    cmds
  }
}
```

## Getting the commands from many pages

```{r}
# Get/parse R commands from each link of each lesson
syllabus <-
  syllabus %>%
  mutate(
    cmds = map(href, get_cmds)
  )
```

```{r results='asis'}
# Display results (with proper heading)
# The remaining content (following this code block) is generated by R.
for (i in 1:max(syllabus$lesson_plan)) {
  cat(
    sprintf("### %s: %s\n",
            syllabus[i,]["lesson_plan"],
            syllabus[i,]["label"])
  )
  cat(
    syllabus[i,]$cmds %>%
      unlist() %>%
      paste(collapse = "")
    )
}
```
